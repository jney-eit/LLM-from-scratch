

context_size: 256
batch_size: 64
loss_function: "CrossEntropy"
optimizer: "AdamW"
learning_rate: 3.0e-4
train_iters: 5000
eval_iters: 100
d_model: 384
num_heads: 6
num_layers: 6
dropout: 0.0 #0.2
